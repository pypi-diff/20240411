# Comparing `tmp/scAtlasVAE-1.0.3a4-py3-none-any.whl.zip` & `tmp/scAtlasVAE-1.0.3a5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,17 +1,17 @@
-Zip file size: 56508 bytes, number of entries: 34
+Zip file size: 57047 bytes, number of entries: 34
 -rw-r--r--  2.0 unx      890 b- defN 24-Jan-04 15:25 scatlasvae/__init__.py
 -rw-r--r--  2.0 unx     1420 b- defN 23-Nov-22 14:20 scatlasvae/_metadata.py
--rw-r--r--  2.0 unx       19 b- defN 24-Apr-10 03:44 scatlasvae/_version.py
+-rw-r--r--  2.0 unx       19 b- defN 24-Apr-11 08:08 scatlasvae/_version.py
 -rw-r--r--  2.0 unx       74 b- defN 24-Feb-14 07:00 scatlasvae/data/__init__.py
 -rw-r--r--  2.0 unx     1549 b- defN 24-Feb-14 07:03 scatlasvae/data/_dataloader.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-04 13:38 scatlasvae/externals/__init__.py
 -rw-r--r--  2.0 unx     1924 b- defN 23-Dec-04 13:38 scatlasvae/externals/_trvae_mmd_loss.py
 -rw-r--r--  2.0 unx       86 b- defN 23-Nov-24 03:53 scatlasvae/model/__init__.py
--rw-r--r--  2.0 unx    81220 b- defN 24-Apr-10 03:44 scatlasvae/model/_gex_model.py
+-rw-r--r--  2.0 unx    93694 b- defN 24-Apr-11 07:58 scatlasvae/model/_gex_model.py
 -rw-r--r--  2.0 unx    31170 b- defN 24-Mar-15 04:57 scatlasvae/model/_primitives.py
 -rw-r--r--  2.0 unx       41 b- defN 23-Nov-22 14:14 scatlasvae/pipeline/__init__.py
 -rw-r--r--  2.0 unx     8777 b- defN 23-Dec-04 13:45 scatlasvae/pipeline/_pipeline.py
 -rw-r--r--  2.0 unx      127 b- defN 23-Nov-22 14:24 scatlasvae/preprocessing/__init__.py
 -rw-r--r--  2.0 unx     3255 b- defN 24-Apr-09 07:43 scatlasvae/preprocessing/_infercnv.py
 -rw-r--r--  2.0 unx    35547 b- defN 24-Jan-02 15:36 scatlasvae/preprocessing/_preprocess.py
 -rw-r--r--  2.0 unx       78 b- defN 24-Jan-05 06:06 scatlasvae/tools/__init__.py
@@ -23,14 +23,14 @@
 -rw-r--r--  2.0 unx     4339 b- defN 24-Jan-04 15:29 scatlasvae/utils/_definitions.py
 -rw-r--r--  2.0 unx    10679 b- defN 23-Nov-22 14:21 scatlasvae/utils/_distributions.py
 -rw-r--r--  2.0 unx     4791 b- defN 24-Mar-21 12:50 scatlasvae/utils/_logger.py
 -rw-r--r--  2.0 unx     7995 b- defN 24-Mar-22 07:27 scatlasvae/utils/_loss.py
 -rw-r--r--  2.0 unx     5680 b- defN 23-Nov-22 14:18 scatlasvae/utils/_parallelizer.py
 -rw-r--r--  2.0 unx     1081 b- defN 23-Nov-22 14:12 scatlasvae/utils/_tensor_utils.py
 -rw-r--r--  2.0 unx     6611 b- defN 24-Mar-22 04:24 scatlasvae/utils/_utilities.py
--rw-r--r--  2.0 unx     1522 b- defN 24-Apr-10 03:45 scAtlasVAE-1.0.3a4.dist-info/LICENSE
--rw-r--r--  2.0 unx     1355 b- defN 24-Apr-10 03:45 scAtlasVAE-1.0.3a4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-10 03:45 scAtlasVAE-1.0.3a4.dist-info/WHEEL
--rw-r--r--  2.0 unx       39 b- defN 24-Apr-10 03:45 scAtlasVAE-1.0.3a4.dist-info/dependency_links.txt
--rw-r--r--  2.0 unx       11 b- defN 24-Apr-10 03:45 scAtlasVAE-1.0.3a4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2941 b- defN 24-Apr-10 03:45 scAtlasVAE-1.0.3a4.dist-info/RECORD
-34 files, 227030 bytes uncompressed, 51750 bytes compressed:  77.2%
+-rw-r--r--  2.0 unx     1522 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1355 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/WHEEL
+-rw-r--r--  2.0 unx       39 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/dependency_links.txt
+-rw-r--r--  2.0 unx       11 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2941 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/RECORD
+34 files, 239504 bytes uncompressed, 52289 bytes compressed:  78.2%
```

## zipnote {}

```diff
@@ -78,26 +78,26 @@
 
 Filename: scatlasvae/utils/_tensor_utils.py
 Comment: 
 
 Filename: scatlasvae/utils/_utilities.py
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a4.dist-info/LICENSE
+Filename: scAtlasVAE-1.0.3a5.dist-info/LICENSE
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a4.dist-info/METADATA
+Filename: scAtlasVAE-1.0.3a5.dist-info/METADATA
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a4.dist-info/WHEEL
+Filename: scAtlasVAE-1.0.3a5.dist-info/WHEEL
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a4.dist-info/dependency_links.txt
+Filename: scAtlasVAE-1.0.3a5.dist-info/dependency_links.txt
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a4.dist-info/top_level.txt
+Filename: scAtlasVAE-1.0.3a5.dist-info/top_level.txt
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a4.dist-info/RECORD
+Filename: scAtlasVAE-1.0.3a5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## scatlasvae/_version.py

```diff
@@ -1 +1 @@
-version = '1.0.3a4'
+version = '1.0.3a5'
```

## scatlasvae/model/_gex_model.py

```diff
@@ -121,14 +121,15 @@
        inject_batch: bool = True,
        inject_label: bool = False,
        inject_additional_batch: bool = True,
        mmd_key: Optional[Literal['batch','additional_batch','both']] = None,
        unlabel_key: str = 'undefined',
        device: Optional[Union[str, torch.device]] = None,
        pretrained_state_dict: Union[str, Optional[Mapping[str, torch.Tensor]]] = None,
+       low_memory_initialization: bool = False,
     ) -> None:
         if device is None:
             device = get_default_device()
         
         super(scAtlasVAE, self).__init__()
         if adata.X.dtype != np.int32 and reconstruction_method in ['zinb', 'nb']:
             mw("adata.X is not of type np.int32. \n" + \
@@ -182,15 +183,15 @@
         self.mmd_key = mmd_key
         self.reconstruction_method = reconstruction_method
         self.constrain_latent_embedding = constrain_latent_embedding
         self.constrain_latent_method = constrain_latent_method
         self.constrain_latent_key = constrain_latent_key
         self.constrain_n_label = constrain_n_label
         self.constrain_n_batch = constrain_n_batch
-
+        self.low_memory_initialization = low_memory_initialization
         self.device=device
 
         self.initialize_dataset()
 
         self.batch_embedding = batch_embedding
         if batch_embedding == "onehot":
             batch_hidden_dim = self.n_batch
@@ -198,14 +199,16 @@
         self.inject_batch = inject_batch
         self.inject_label = inject_label
         self.inject_additional_batch = inject_additional_batch
         self.encode_libsize = encode_libsize
         self.decode_libsize = decode_libsize
         self.dispersion = dispersion
 
+        
+
 
         self.fcargs = dict(
             bias           = bias,
             dropout_rate   = dropout_rate,
             use_batch_norm = use_batch_norm,
             use_layer_norm = use_layer_norm,
             activation_fn  = activation_fn,
@@ -670,63 +673,111 @@
             additional_label_categories = [np.array(x.codes) for x in self.additional_label_category]
         if self.additional_batch_keys is not None:
             for e,i in enumerate(self.additional_batch_keys):
                 if i not in self.adata.obs.columns:
                     raise ValueError(f"additional_batch_keys {i} is not found in AnnData obs")
             additional_batch_categories = [np.array(x.codes) for x in self.additional_batch_category]
 
-
-        if self.constrain_latent_embedding and self.constrain_latent_key in self.adata.obsm.keys():
-            P = self.adata.obsm[self.constrain_latent_key]
-            if additional_batch_categories is not None:
-                if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
-                    _dataset = list(zip(P, batch_categories, label_categories, *additional_label_categories, *additional_batch_categories))
-                elif batch_categories is not None and label_categories is not None:
-                    _dataset = list(zip(P, batch_categories, label_categories, *additional_batch_categories))
-                elif batch_categories is not None:
-                    _dataset = list(zip(P, batch_categories, *additional_batch_categories))
-                elif label_categories is not None:
-                    _dataset = list(zip(P, label_categories, *additional_batch_categories))
+        if self.low_memory_initialization:
+            if self.constrain_latent_embedding and self.constrain_latent_key in self.adata.obsm.keys():
+                P = self.adata.obsm[self.constrain_latent_key]
+                if additional_batch_categories is not None:
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(P, batch_categories, label_categories, *additional_label_categories, *additional_batch_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(P, batch_categories, label_categories, *additional_batch_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(P, batch_categories, *additional_batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(P, label_categories, *additional_batch_categories))
+                    else:
+                        _dataset = list(zip(P, *additional_batch_categories))
                 else:
-                    _dataset = list(zip(P, *additional_batch_categories))
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(P, batch_categories, label_categories, *additional_label_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(P, batch_categories, label_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(P, batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(P, label_categories))
+                    else:
+                        _dataset = list(zip(P))
             else:
-                if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
-                    _dataset = list(zip(P, batch_categories, label_categories, *additional_label_categories))
-                elif batch_categories is not None and label_categories is not None:
-                    _dataset = list(zip(P, batch_categories, label_categories))
-                elif batch_categories is not None:
-                    _dataset = list(zip(P, batch_categories))
-                elif label_categories is not None:
-                    _dataset = list(zip(P, label_categories))
+                if additional_batch_categories is not None:
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(batch_categories, label_categories, *additional_label_categories, *additional_batch_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(batch_categories, label_categories, *additional_batch_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(batch_categories, *additional_batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(label_categories, *additional_batch_categories))
+                    else:
+                        _dataset = list(zip(*additional_batch_categories))
                 else:
-                    _dataset = list(zip(P))
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(batch_categories, label_categories, *additional_label_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(batch_categories, label_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(label_categories))
+                    else:
+                        _dataset = list(X)
         else:
-            if additional_batch_categories is not None:
-                if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
-                    _dataset = list(zip(batch_categories, label_categories, *additional_label_categories, *additional_batch_categories))
-                elif batch_categories is not None and label_categories is not None:
-                    _dataset = list(zip(batch_categories, label_categories, *additional_batch_categories))
-                elif batch_categories is not None:
-                    _dataset = list(zip(batch_categories, *additional_batch_categories))
-                elif label_categories is not None:
-                    _dataset = list(zip(label_categories, *additional_batch_categories))
+            if self.constrain_latent_embedding and self.constrain_latent_key in self.adata.obsm.keys():
+                P = self.adata.obsm[self.constrain_latent_key]
+                if additional_batch_categories is not None:
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(X, P, batch_categories, label_categories, *additional_label_categories, *additional_batch_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(X, P, batch_categories, label_categories, *additional_batch_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(X, P, batch_categories, *additional_batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(X, P, label_categories, *additional_batch_categories))
+                    else:
+                        _dataset = list(zip(X, P, *additional_batch_categories))
                 else:
-                    _dataset = list(zip(*additional_batch_categories))
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(X, P, batch_categories, label_categories, *additional_label_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(X, P, batch_categories, label_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(X, P, batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(X, P, label_categories))
+                    else:
+                        _dataset = list(zip(X, P))
             else:
-                if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
-                    _dataset = list(zip(batch_categories, label_categories, *additional_label_categories))
-                elif batch_categories is not None and label_categories is not None:
-                    _dataset = list(zip(batch_categories, label_categories))
-                elif batch_categories is not None:
-                    _dataset = list(zip(batch_categories))
-                elif label_categories is not None:
-                    _dataset = list(zip(label_categories))
+                if additional_batch_categories is not None:
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(X, batch_categories, label_categories, *additional_label_categories, *additional_batch_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(X, batch_categories, label_categories, *additional_batch_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(X, batch_categories, *additional_batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(X, label_categories, *additional_batch_categories))
+                    else:
+                        _dataset = list(zip(X, *additional_batch_categories))
                 else:
-                    _dataset = list(X)
-
+                    if batch_categories is not None and label_categories is not None and additional_label_categories is not None:
+                        _dataset = list(zip(X, batch_categories, label_categories, *additional_label_categories))
+                    elif batch_categories is not None and label_categories is not None:
+                        _dataset = list(zip(X, batch_categories, label_categories))
+                    elif batch_categories is not None:
+                        _dataset = list(zip(X, batch_categories))
+                    elif label_categories is not None:
+                        _dataset = list(zip(X, label_categories))
+                    else:
+                        _dataset = list(X)
+    
         
         _shuffle_indices = list(range(len(_dataset)))
         np.random.shuffle(_shuffle_indices)
         self._dataset = np.array([_dataset[i] for i in _shuffle_indices], dtype=object)
 
         self._shuffle_indices = np.array(
             [x for x, _ in sorted(zip(range(len(_dataset)), _shuffle_indices), key=lambda x: x[1])]
@@ -1573,104 +1624,257 @@
             method=method,
 
         )
 
     def _prepare_batch(self, batch_indices):
         P = None
         batch_data = self._dataset[batch_indices.cpu().numpy()]
-
-        X = self.adata.X[
-            self._shuffled_indices_inverse[
-                batch_indices.cpu().numpy()
-            ]
-        ]
         batch_index, label_index, additional_label_index, additional_batch_index = None, None, None, None
-        if self.n_batch > 0 or self.n_label > 0:
-            if not (isinstance(batch_data, Iterable) and len(batch_data) > 1):
-                raise ValueError("batch_data is not iterable or has only one element")
-            if self.n_additional_batch_ is not None:
-                if self.n_batch > 0 and self.n_label > 0 and self.n_additional_label is not None:
-                    if self.constrain_latent_embedding:
-                        P, batch_index, label_index, additional_label_index, additional_batch_index = (
-                            get_k_elements(batch_data,0),
-                            get_k_elements(batch_data,1),
-                            get_k_elements(batch_data,2),
-                            get_elements(batch_data,3, len(self.n_additional_label)),
-                            get_last_k_elements(batch_data,3+len(self.n_additional_label))
-                        )
-                    else:
-                        batch_index, label_index, additional_label_index, additional_batch_index = (
-                            get_k_elements(batch_data,0),
-                            get_k_elements(batch_data,1),
-                            get_elements(batch_data,2, len(self.n_additional_label)),
-                            get_last_k_elements(batch_data,2+len(self.n_additional_label))
-                        )
-                    additional_label_index = list(np.vstack(additional_label_index).T.astype(int))
-                elif self.n_batch > 0 and self.n_label > 0:
-                    if self.constrain_latent_embedding:
-                        P, batch_index, label_index, additional_batch_index = (
-                            get_k_elements(batch_data,0),
-                            get_k_elements(batch_data,1),
-                            get_k_elements(batch_data,2),
-                            get_last_k_elements(batch_data,3)
-                        )
-                    else:
-                        batch_index, label_index, additional_batch_index = (
-                            get_k_elements(batch_data,0),
-                            get_k_elements(batch_data,1),
-                            get_last_k_elements(batch_data,2)
-                        )
-                elif self.n_batch > 0:
-                    if self.constrain_latent_embedding:
-                        P, batch_index, additional_batch_index = (
-                            get_k_elements(batch_data,0),
-                            get_k_elements(batch_data,1),
-                            get_last_k_elements(batch_data,2)
-                        )
-                    else:
-                        batch_index, additional_batch_index = get_k_elements(batch_data,0), get_last_k_elements(batch_data,1)
-                elif self.n_label > 0:
-                    if self.constrain_latent_embedding:
-                        P, label_index, additional_batch_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1), get_last_k_elements(batch_data,2)
-                    else:
-                        label_index, additional_batch_index = get_k_elements(batch_data,0), get_last_k_elements(batch_data,2)
-                additional_batch_index = list(np.vstack(additional_batch_index).T.astype(int))
-            else:
-                if self.n_batch > 0 and self.n_label > 0 and self.n_additional_label is not None:
-                    if self.constrain_latent_embedding:
-                        P, batch_index, label_index, additional_label_index = (
-                            get_k_elements(batch_data,0),
-                            get_k_elements(batch_data,1),
-                            get_k_elements(batch_data,2),
-                            get_last_k_elements(batch_data,3)
+        
+        if self.low_memory_initialization:
+            X = self.adata.X[
+                self._shuffled_indices_inverse[
+                    batch_indices.cpu().numpy()
+                ]
+            ]
+
+            if self.n_batch > 0 or self.n_label > 0:
+                if not (isinstance(batch_data, Iterable) and len(batch_data) > 1):
+                    raise ValueError("batch_data is not iterable or has only one element")
+                if self.n_additional_batch_ is not None:
+                    if self.n_batch > 0 and self.n_label > 0 and self.n_additional_label is not None:
+                        if self.constrain_latent_embedding:
+                            P, batch_index, label_index, additional_label_index, additional_batch_index = (
+                                get_k_elements(batch_data,0),
+                                get_k_elements(batch_data,1),
+                                get_k_elements(batch_data,2),
+                                get_elements(batch_data,3, len(self.n_additional_label)),
+                                get_last_k_elements(batch_data,3+len(self.n_additional_label))
+                            )
+                        else:
+                            batch_index, label_index, additional_label_index, additional_batch_index = (
+                                get_k_elements(batch_data,0),
+                                get_k_elements(batch_data,1),
+                                get_elements(batch_data,2, len(self.n_additional_label)),
+                                get_last_k_elements(batch_data,2+len(self.n_additional_label))
+                            )
+                        additional_label_index = list(np.vstack(additional_label_index).T.astype(int))
+                    elif self.n_batch > 0 and self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            P, batch_index, label_index, additional_batch_index = (
+                                get_k_elements(batch_data,0),
+                                get_k_elements(batch_data,1),
+                                get_k_elements(batch_data,2),
+                                get_last_k_elements(batch_data,3)
+                            )
+                        else:
+                            batch_index, label_index, additional_batch_index = (
+                                get_k_elements(batch_data,0),
+                                get_k_elements(batch_data,1),
+                                get_last_k_elements(batch_data,2)
+                            )
+                    elif self.n_batch > 0:
+                        if self.constrain_latent_embedding:
+                            P, batch_index, additional_batch_index = (
+                                get_k_elements(batch_data,0),
+                                get_k_elements(batch_data,1),
+                                get_last_k_elements(batch_data,2)
+                            )
+                        else:
+                            batch_index, additional_batch_index = get_k_elements(batch_data,0), get_last_k_elements(batch_data,1)
+                    elif self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            P, label_index, additional_batch_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1), get_last_k_elements(batch_data,2)
+                        else:
+                            label_index, additional_batch_index = get_k_elements(batch_data,0), get_last_k_elements(batch_data,2)
+                    additional_batch_index = list(np.vstack(additional_batch_index).T.astype(int))
+                else:
+                    if self.n_batch > 0 and self.n_label > 0 and self.n_additional_label is not None:
+                        if self.constrain_latent_embedding:
+                            P, batch_index, label_index, additional_label_index = (
+                                get_k_elements(batch_data,0),
+                                get_k_elements(batch_data,1),
+                                get_k_elements(batch_data,2),
+                                get_last_k_elements(batch_data,3)
+                            )
+                        else:
+                            batch_index, label_index, additional_label_index = (
+                                get_k_elements(batch_data,0),
+                                get_k_elements(batch_data,1),
+                                get_last_k_elements(batch_data,2)
+                            )
+                        additional_label_index = list(np.vstack(additional_label_index).T.astype(int))
+                    elif self.n_batch > 0 and self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            P, batch_index, label_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1), get_k_elements(batch_data,2)
+                        else:
+                            batch_index, label_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1)
+                    elif self.n_batch > 0:
+                        if self.constrain_latent_embedding:
+                            P, batch_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1)
+                        else:
+                            batch_index = get_k_elements(batch_data,0)
+                    elif self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            P, label_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1)
+                        else:
+                            label_index = get_k_elements(batch_data,0)
+        
+            X = torch.tensor(X.toarray() if issparse(X) else X)
+        else:
+            if self.n_batch > 0 or self.n_label > 0:
+                if not isinstance(batch_data, Iterable) and len(batch_data) > 1:
+                    raise ValueError()
+                if self.n_additional_batch_ is not None:
+                    if (
+                        self.n_batch > 0
+                        and self.n_label > 0
+                        and self.n_additional_label is not None
+                    ):
+                        if self.constrain_latent_embedding:
+                            (
+                                X,
+                                P,
+                                batch_index,
+                                label_index,
+                                additional_label_index,
+                                additional_batch_index,
+                            ) = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_k_elements(batch_data, 3),
+                                get_elements(batch_data, 4, len(self.n_additional_label)),
+                                get_last_k_elements(batch_data, 4 + len(self.n_additional_label)),
+                            )
+                        else:
+                            (
+                                X,
+                                batch_index,
+                                label_index,
+                                additional_label_index,
+                                additional_batch_index,
+                            ) = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_elements(batch_data, 3, len(self.n_additional_label)),
+                                get_last_k_elements(batch_data, 3 + len(self.n_additional_label)),
+                            )
+                        additional_label_index = list(
+                            np.vstack(additional_label_index).T.astype(int)
                         )
-                    else:
-                        batch_index, label_index, additional_label_index = (
-                            get_k_elements(batch_data,0),
-                            get_k_elements(batch_data,1),
-                            get_last_k_elements(batch_data,2)
+                    elif self.n_batch > 0 and self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            X, P, batch_index, label_index, additional_batch_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_k_elements(batch_data, 3),
+                                get_last_k_elements(batch_data, 4),
+                            )
+                        else:
+                            X, batch_index, label_index, additional_batch_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_last_k_elements(batch_data, 3),
+                            )
+                    elif self.n_batch > 0:
+                        if self.constrain_latent_embedding:
+                            X, P, batch_index, additional_batch_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_last_k_elements(batch_data, 3),
+                            )
+                        else:
+                            X, batch_index, additional_batch_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_last_k_elements(batch_data, 2),
+                            )
+                    elif self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            X, P, label_index, additional_batch_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_last_k_elements(batch_data, 3),
+                            )
+                        else:
+                            X, label_index, additional_batch_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_last_k_elements(batch_data, 2),
+                            )
+                    additional_batch_index = list(
+                        np.vstack(additional_batch_index).T.astype(int)
+                    )
+                else:
+                    if (
+                        self.n_batch > 0
+                        and self.n_label > 0
+                        and self.n_additional_label is not None
+                    ):
+                        if self.constrain_latent_embedding:
+                            X, P, batch_index, label_index, additional_label_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_k_elements(batch_data, 3),
+                                get_last_k_elements(batch_data, 4),
+                            )
+                        else:
+                            X, batch_index, label_index, additional_label_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_last_k_elements(batch_data, 3),
+                            )
+                        additional_label_index = list(
+                            np.vstack(additional_label_index).T.astype(int)
                         )
-                    additional_label_index = list(np.vstack(additional_label_index).T.astype(int))
-                elif self.n_batch > 0 and self.n_label > 0:
-                    if self.constrain_latent_embedding:
-                        P, batch_index, label_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1), get_k_elements(batch_data,2)
-                    else:
-                        batch_index, label_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1)
-                elif self.n_batch > 0:
-                    if self.constrain_latent_embedding:
-                        P, batch_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1)
-                    else:
-                        batch_index = get_k_elements(batch_data,0)
-                elif self.n_label > 0:
-                    if self.constrain_latent_embedding:
-                        P, label_index = get_k_elements(batch_data,0), get_k_elements(batch_data,1)
-                    else:
-                        label_index = get_k_elements(batch_data,0)
+                    elif self.n_batch > 0 and self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            X, P, batch_index, label_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                                get_k_elements(batch_data, 3),
+                            )
+                        else:
+                            X, batch_index, label_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                            )
+                    elif self.n_batch > 0:
+                        if self.constrain_latent_embedding:
+                            X, P, batch_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                            )
+                        else:
+                            X, batch_index = get_k_elements(batch_data, 0), get_k_elements(batch_data, 1)
+                    elif self.n_label > 0:
+                        if self.constrain_latent_embedding:
+                            X, P, label_index = (
+                                get_k_elements(batch_data, 0),
+                                get_k_elements(batch_data, 1),
+                                get_k_elements(batch_data, 2),
+                            )
+                        else:
+                            X, label_index = get_k_elements(batch_data, 0), get_k_elements(batch_data, 1)
+
+            X = torch.tensor(
+                np.vstack(list(map(lambda x: x.toarray() if issparse(x) else x, X)))
+            )
 
-        X = torch.tensor(X.toarray() if issparse(X) else X)
         if self.constrain_latent_embedding:
             P = torch.tensor(np.vstack(P)).type(torch.FloatTensor).to(self.device)
         if self.n_label > 0:
             label_index = torch.tensor(label_index)
             if not isinstance(label_index, torch.FloatTensor):
                 label_index = label_index.type(torch.FloatTensor)
             label_index = label_index.to(self.device).unsqueeze(1)
```

## Comparing `scAtlasVAE-1.0.3a4.dist-info/LICENSE` & `scAtlasVAE-1.0.3a5.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `scAtlasVAE-1.0.3a4.dist-info/METADATA` & `scAtlasVAE-1.0.3a5.dist-info/METADATA`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: scAtlasVAE
-Version: 1.0.3a4
+Version: 1.0.3a5
 Summary: scAtlasVAE: a deep learning framework for atlas-scale scRNA-seq integration and analysis
 Home-page: https://github.com/WanluLiuLab/scAtlasVAE
 Author: Ziwei Xue
 Author-email: xueziweisz@gmail.com
 License: UNKNOWN
 Download-URL: https://github.com/WanluLiuLab/scAtlasVAE
 Platform: UNKNOWN
```

## Comparing `scAtlasVAE-1.0.3a4.dist-info/RECORD` & `scAtlasVAE-1.0.3a5.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 scatlasvae/__init__.py,sha256=RLkNezvb5hYNMAZAYwsR3WXz6tNiM2mhceuvU2m1V9o,890
 scatlasvae/_metadata.py,sha256=YKuaQknWHvdKviwVf3XcxuIX9xEV7raH_hMSxTXpyKg,1420
-scatlasvae/_version.py,sha256=WvsCdJ0MIcRU_WXCrJep3Pbtkow2XVVsEGGSzV8kRvo,19
+scatlasvae/_version.py,sha256=x2CsG9w3-5OiQ9EoKgi-8fvFOO-06ZXoq9WvrZNiLlE,19
 scatlasvae/data/__init__.py,sha256=DRGPdhwDwndVwF029g9ITqgrxSiX0kTdm_6wZshyRgQ,74
 scatlasvae/data/_dataloader.py,sha256=3z02t6ufCxjZvQRYNXfKYE8Pl2sXzyGFSTWGqPsV6IU,1549
 scatlasvae/externals/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scatlasvae/externals/_trvae_mmd_loss.py,sha256=kNRkIDk4Aid1vb9dEmXii0F6HRhLYEkar3k_KfRyjk4,1924
 scatlasvae/model/__init__.py,sha256=y_Vu4dtOU0crMGYbg4in9cqFw3W71AhtNs8dMd-Hd4Y,86
-scatlasvae/model/_gex_model.py,sha256=b6hZqY0xYdBAfe90J_0KeaqLjUYCiwberx7UaMpbjzc,81220
+scatlasvae/model/_gex_model.py,sha256=Ip-XVexUn2T-3RObANSKAc2r8mVfujokHVavBq9m2SM,93694
 scatlasvae/model/_primitives.py,sha256=i0sQY4rU5eaMuswzcvZHVz6JHpsRrVvbVp2u2QemdsY,31170
 scatlasvae/pipeline/__init__.py,sha256=Gj_IP3ZGzWXcQcwf9wVJN9sxCL3LBik_GkKe77bQ4uw,41
 scatlasvae/pipeline/_pipeline.py,sha256=dvEfsFxeLskGPDg1rIUZE8USIxsqo-CC7gCVwDb8Bnc,8777
 scatlasvae/preprocessing/__init__.py,sha256=LJWHQgT8w93fDVVa5e-5DFv0UEph3wv-P6Oqeb4xOP8,127
 scatlasvae/preprocessing/_infercnv.py,sha256=Yp1bJSchtZ-4rMcjro6Ax8PfRuWYStbEvQtXIYuQXqY,3255
 scatlasvae/preprocessing/_preprocess.py,sha256=nES1QPOx1ee2lTM-W_qjEyly0IAoQ8SZd-3vI3urCM0,35547
 scatlasvae/tools/__init__.py,sha256=eyRiflnSSm25qdZo5cmqECvdSX8TLPYLr4MBgrhEqog,78
@@ -22,13 +22,13 @@
 scatlasvae/utils/_definitions.py,sha256=5CXPI1ikSx7FInKhZ-YwnvvuCIpa8f6OP2ddKZAl-qQ,4339
 scatlasvae/utils/_distributions.py,sha256=-Ige2YaFToBf9R68LS57g-TsdUK4s4Cm6zPC_EZBmq4,10679
 scatlasvae/utils/_logger.py,sha256=05cqq-6jTFyY13vrJhNWlu2Ryt-DXrbz6NpWGgVomQ0,4791
 scatlasvae/utils/_loss.py,sha256=DkaxjFBwmt-U435HfoXL06zWlai_Psm1dj-5B-j6vRQ,7995
 scatlasvae/utils/_parallelizer.py,sha256=BAX_FMAlifrbhp356te-GFuHIYUO5aDChlFMGM_qY1Y,5680
 scatlasvae/utils/_tensor_utils.py,sha256=RSwy0czCGgGFdk8mvQplK_DL4VN0zA-M81f3zFfSdCU,1081
 scatlasvae/utils/_utilities.py,sha256=L-V1XnxsBsCHgaFCZlQ2Wyt6NzeeZuTWCQPumDYkQd0,6611
-scAtlasVAE-1.0.3a4.dist-info/LICENSE,sha256=iIPK3YfcATgHwXIjFIPvNF0FUR7vP-S2mOJmlv5H0lI,1522
-scAtlasVAE-1.0.3a4.dist-info/METADATA,sha256=7rjr8vU9Uh9o9YyA6e5iQmTkL4tte17tWb9VF3GGnbI,1355
-scAtlasVAE-1.0.3a4.dist-info/WHEEL,sha256=Xo9-1PvkuimrydujYJAjF7pCkriuXBpUPEjma1nZyJ0,92
-scAtlasVAE-1.0.3a4.dist-info/dependency_links.txt,sha256=ruee1cEBfajPwjguNMor_ix7qykV-lvgrkqssMcjBXQ,39
-scAtlasVAE-1.0.3a4.dist-info/top_level.txt,sha256=CEiwZxZLLn_PrRCJEi6VHH2UvdtCzoB4i9WeEGf5IMY,11
-scAtlasVAE-1.0.3a4.dist-info/RECORD,,
+scAtlasVAE-1.0.3a5.dist-info/LICENSE,sha256=iIPK3YfcATgHwXIjFIPvNF0FUR7vP-S2mOJmlv5H0lI,1522
+scAtlasVAE-1.0.3a5.dist-info/METADATA,sha256=N2cRNDjxmoxNG438dQV0WMgP2OG3HKTGRj816ethQCY,1355
+scAtlasVAE-1.0.3a5.dist-info/WHEEL,sha256=Xo9-1PvkuimrydujYJAjF7pCkriuXBpUPEjma1nZyJ0,92
+scAtlasVAE-1.0.3a5.dist-info/dependency_links.txt,sha256=ruee1cEBfajPwjguNMor_ix7qykV-lvgrkqssMcjBXQ,39
+scAtlasVAE-1.0.3a5.dist-info/top_level.txt,sha256=CEiwZxZLLn_PrRCJEi6VHH2UvdtCzoB4i9WeEGf5IMY,11
+scAtlasVAE-1.0.3a5.dist-info/RECORD,,
```

